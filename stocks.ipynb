{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from plotly import offline as plotly\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "plotly.init_notebook_mode(True)\n",
    "np = pd.np\n",
    "\n",
    "### Hyper Parameters\n",
    "LEARNING_RATE = 0.001 # 0.01 and 0.005 worked eventually\n",
    "BATCH_SIZE = 25000\n",
    "NUM_EPOCHS = 1\n",
    "INPUT_SIZE = NUM_FEATURES = 1\n",
    "HIDDEN_SIZE = 200\n",
    "NUM_CLASSES = 2\n",
    "SEQ_LENGTH = 10\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:55<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "def read_returns(pair):\n",
    "    path = f's3://mikeokslonger-ticks/returns.parquet/pair={pair}/part.0.parquet'\n",
    "    df = pd.read_parquet(path, columns=['time', 'relative_returns', 'buy', 'quantity', 'price'])\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    one_hot = np.array([[1, 0],\n",
    "                       [0, 1]], dtype='float32')\n",
    "    df['buy'] = df['buy'].astype(float)\n",
    "    df['label'] = (df.shift(-1)['relative_returns'] > 0.).astype(int)\n",
    "    df['label_onehot'] = df['label'].apply(lambda i: one_hot[i])\n",
    "    df['time'] = (df['time'] - 20180101000000).astype(float)\n",
    "    return df[1:]\n",
    "\n",
    "pairs = ['ADX-USD', 'AIR-USD', 'AMM-USD', 'ATB-USD', 'ATM-USD', 'B2X-USD', 'BCC-USD', 'BCH-USD', 'BCN-USD', 'BMC-USD', 'BNT-USD', 'BQX-USD', 'BTCA-USD', 'BTC-USD', 'BTG-USD', 'BTM-USD', 'BTX-USD', 'CAT-USD', 'CDT-USD', 'CLD-USD', 'CL-USD', 'CND-USD', 'CTR-USD', 'CVC-USD', 'DASH-USD', 'DATA-USD', 'DCN-USD', 'DGB-USD', 'DIM-USD', 'DOGE-USD', 'EBTCOLD-USD', 'EDO-USD', 'EMGO-USD', 'ENJ-USD', 'EOS-USD', 'ETC-USD', 'ETH-USD', 'ETP-USD', 'EVX-USD', 'FUEL-USD', 'FUN-USD', 'ICOS-USD', 'ICX-USD', 'KMD-USD', 'LOC-USD', 'LSK-USD', 'LTC-USD', 'MAID-USD', 'MANA-USD', 'MCO-USD', 'NEO-USD', 'NGC-USD', 'NXT-USD', 'OAX-USD', 'OMG-USD', 'PLR-USD', 'PPC-USD', 'PRG-USD', 'QTUM-USD', 'SMART-USD', 'SMS-USD', 'SNC-USD', 'SNT-USD', 'STRAT-USD', 'STU-USD', 'STX-USD', 'SUB-USD', 'SUR-USD', 'SWFTC-USD', 'TNT-USD', 'TRX-USD', 'UGT-USD', 'UTT-USD', 'VEN-USD', 'VERI-USD', 'VIB-USD', 'WMGO-USD', 'WRC-USD', 'XDN-USD', 'XEM-USD', 'XMR-USD', 'XTZ-USD', 'XUC-USD', 'XVG-USD', 'ZEC-USD', 'ZRX-USD', 'ZSC-USD']\n",
    "pairs = pairs\n",
    "df = pd.concat([create_features(read_returns(pair)) for pair in tqdm.tqdm(pairs)]) # Full dataset\n",
    "df = df[df.relative_returns.abs() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticks(Dataset):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.x_data = data[:, 1:2].copy().astype('float32')\n",
    "        self.y_data = data[:, -1].copy()#.astype('int')\n",
    "        \n",
    "        indices = pd.DataFrame(data[:, -2] == 0,columns=['isnegative']).reset_index()\n",
    "        positive_indices = indices[~indices.isnegative]['index']\n",
    "        negative_indices = indices[indices.isnegative]['index']\n",
    "        negative_indices_resampled = negative_indices.sample(frac=len(positive_indices)/len(negative_indices))\n",
    "        self.new_indices = pd.np.concatenate([positive_indices, negative_indices_resampled])\n",
    "        self.new_indices.sort()\n",
    "        \n",
    "        self.len = len(self.new_indices) - SEQ_LENGTH - ((len(self.new_indices) - SEQ_LENGTH) % batch_size)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        new_index = self.new_indices[index]\n",
    "        x = self.x_data[new_index: new_index + SEQ_LENGTH]\n",
    "        return x, self.y_data[new_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "test_validation_split = int(len(df) * 0.8)\n",
    "dataset_train = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[:test_validation_split], BATCH_SIZE)\n",
    "dataset_test = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values[test_validation_split:], BATCH_SIZE)\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Model\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### (LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda() # Hidden\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda() # Cell state\n",
    "        _, (h_out, _) = self.lstm(x, (h0, c0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        activated = self.sig(out)\n",
    "        return activated\n",
    "\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "test_predicted_positives = []\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "lstm = LSTM(NUM_CLASSES, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS).cuda()\n",
    "#lstm.load_state_dict(torch.load('models/180.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEUniformLoss(torch.nn.BCELoss):\n",
    "    def forward(self, input, target):\n",
    "        normal_result = super(BCEUniformLoss, self).forward(input, target)\n",
    "        skew = torch.abs(input.data[:, [1]].sum() - trainY[:, [1]].sum())\n",
    "        adjustment_factor = (skew / trainY[:, [1]].sum()) ** 2\n",
    "        return normal_result + normal_result * adjustment_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#loss_fn = torch.nn.BCELoss()\n",
    "loss_fn = BCEUniformLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 63/201 [00:28<01:02,  2.22it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in list(range(0, 50)):\n",
    "    correct = 0\n",
    "    num_positive_returns = 0\n",
    "    predicted_positive_returns = 0\n",
    "    num_observations = 0\n",
    "    for i, (trainX, trainY) in tqdm.tqdm(enumerate(dataloader_train), total=len(dataset_train) // BATCH_SIZE):\n",
    "        trainX, trainY = Variable(trainX).cuda(), Variable(trainY).cuda()\n",
    "        outputs = lstm(trainX)\n",
    "        correct += torch.max(outputs.data, 1)[1].eq(torch.max(trainY.data, 1)[1]).sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "        num_positive_returns += trainY[:, [1]].sum()\n",
    "        num_observations += len(trainY)\n",
    "\n",
    "    accuracies.append(correct / len(dataloader_train.dataset))\n",
    "    losses.append(loss.cpu().data[0])\n",
    "    num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "\n",
    "    clear_output(True)\n",
    "    print(f'epoch {epoch + 1}/{NUM_EPOCHS}')\n",
    "    print(f'actual positive returns {num_positive_returns}/{num_observations}: {num_positive_returns/num_observations}')\n",
    "    print(f'predicted positive_returns {predicted_positive_returns}/{num_observations}: {predicted_positive_returns/num_observations}')\n",
    "    \n",
    "    correct = 0\n",
    "    num_positive_returns = 0\n",
    "    predicted_positive_returns = 0\n",
    "    num_observations = 0\n",
    "    for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "        testX, testY = Variable(testX).cuda(), Variable(testY).cuda()\n",
    "        outputs = lstm(testX)\n",
    "        predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "        correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "        predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "        num_positive_returns += testY[:, [1]].sum()\n",
    "\n",
    "    loss = loss_fn(outputs, trainY)\n",
    "    accuracy = correct / len(dataloader_test.dataset)\n",
    "    test_accuracies.append(accuracy)\n",
    "    num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "    test_predicted_positives.append(predicted_positive_returns/len(dataloader_test.dataset))\n",
    "    \n",
    "    print(f'loss: {loss.data[0]}, accuracy: {accuracy}')\n",
    "    print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "    print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')\n",
    "    \n",
    "    plotly.iplot(go.Figure(data=[go.Scatter(x=list(range(len(losses))), y=losses, name='loss'),\n",
    "                                 go.Scatter(x=list(range(len(accuracies))), y=accuracies, name='train_accuracy', yaxis='y2'),\n",
    "                                 go.Scatter(x=list(range(len(test_accuracies))), y=test_accuracies, name='test_accuracy', yaxis='y2'),\n",
    "                                 go.Scatter(x=list(range(len(test_predicted_positives))), y=test_predicted_positives, name='test_predicted_positives', yaxis='y2')],\n",
    "                           layout=go.Layout(yaxis={'title': 'loss'}, yaxis2={'title': 'accuracy', 'overlaying': 'y', 'side': 'right'})))\n",
    "    plotly.plot(go.Figure(data=[go.Scatter(x=list(range(len(losses))), y=losses, name='loss'),\n",
    "                                go.Scatter(x=list(range(len(accuracies))), y=accuracies, name='train_accuracy', yaxis='y2'),\n",
    "                                go.Scatter(x=list(range(len(test_accuracies))), y=test_accuracies, name='test_accuracy', yaxis='y2'),\n",
    "                                go.Scatter(x=list(range(len(test_predicted_positives))), y=test_predicted_positives, name='test_predicted_positives', yaxis='y2')],\n",
    "                          layout=go.Layout(yaxis={'title': 'loss'}, yaxis2={'title': 'accuracy', 'overlaying': 'y', 'side': 'right'})),\n",
    "               filename=f'models/training/training{epoch}.html')\n",
    "    \n",
    "    df = pd.DataFrame(outputs.data.cpu().numpy()).assign(p1=lambda x: x[1] / (x[0] + x[1])).assign(y=1).sample(n=500)\n",
    "    plotly.iplot(go.Figure(data=[go.Scatter(x=df.p1, y=df.y, mode='markers')],\n",
    "                           layout=go.Layout(xaxis=dict(range=[0, 1]), yaxis=dict(range=[0, 2]))))\n",
    "    plotly.plot(go.Figure(data=[go.Scatter(x=df.p1, y=df.y, mode='markers')],\n",
    "                           layout=go.Layout(xaxis=dict(range=[0, 1]), yaxis=dict(range=[0, 2]))),\n",
    "                filename=f'models/predictions/scatter{epoch}.html')\n",
    "\n",
    "    torch.save(lstm.state_dict(), f'models/model{epoch}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:05<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5318581461906433, accuracy: 0.7052266666666667\n",
      "actual positive returns 260951.0/525000: 0.49704952380952383\n",
      "predicted positive_returns 368879/525000: 0.7026266666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_positive_returns = 0\n",
    "predicted_positive_returns = 0\n",
    "num_observations = 0\n",
    "for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "    testX, testY = Variable(testX).cuda(), Variable(testY).cuda()\n",
    "    outputs = lstm(testX)\n",
    "    predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "    correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "    predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "    num_positive_returns += testY[:, [1]].sum()\n",
    "\n",
    "loss = loss_fn(outputs, testY)\n",
    "accuracy = correct / len(dataloader_test.dataset)\n",
    "num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "\n",
    "print(f'loss: {loss.data[0]}, accuracy: {accuracy}')\n",
    "print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_state_dict(torch.load('models/2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
