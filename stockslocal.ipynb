{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from plotly import offline as plotly\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "plotly.init_notebook_mode(True)\n",
    "np = pd.np\n",
    "\n",
    "### Hyper Parameters\n",
    "LEARNING_RATE = 0.001 # 0.01 and 0.005 worked eventually\n",
    "BATCH_SIZE = 100000\n",
    "NUM_EPOCHS = 1\n",
    "INPUT_SIZE = NUM_FEATURES = 1\n",
    "HIDDEN_SIZE = 200\n",
    "NUM_CLASSES = 2\n",
    "SEQ_LENGTH = 10\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_returns(pair):\n",
    "    try:\n",
    "        path = f's3://mikeokslonger-ticks/returns.parquet/pair={pair}/part.0.parquet'\n",
    "        path = f'/home/mikeokslonger/data_unseen/returns.parquet/pair={pair}/part.0.parquet'\n",
    "        path = f'/home/mikeokslonger/data/returns.parquet/pair={pair}/part.0.parquet'\n",
    "        df = pd.read_parquet(path, columns=['time', 'relative_returns', 'buy', 'quantity', 'price'], engine='fastparquet')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "def create_features(df):\n",
    "    if df is None:\n",
    "        return None\n",
    "    one_hot = np.array([[1, 0],\n",
    "                       [0, 1]], dtype='float32')\n",
    "    return df.assign(buy=lambda x: x.buy.astype(float)) \\\n",
    "        .assign(label=lambda x: (x.shift(-1).relative_returns > 0.).astype(int)) \\\n",
    "        .assign(label_onehot=lambda x: x['label'].apply(lambda i: one_hot[i])) \\\n",
    "        .assign(time=lambda x: (x['time'] - 20180101000000).astype(float))[1:]\n",
    "\n",
    "def filter_null_returns(df):\n",
    "    return df[df.relative_returns.abs() > 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:36<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "pairs = ['ADX-USD', 'AIR-USD', 'AMM-USD', 'ATB-USD', 'ATM-USD', 'B2X-USD', 'BCC-USD', 'BCH-USD', 'BCN-USD', 'BMC-USD', 'BNT-USD', 'BQX-USD', 'BTCA-USD', 'BTC-USD', 'BTG-USD', 'BTM-USD', 'BTX-USD', 'CAT-USD', 'CDT-USD', 'CLD-USD', 'CL-USD', 'CND-USD', 'CTR-USD', 'CVC-USD', 'DASH-USD', 'DATA-USD', 'DCN-USD', 'DGB-USD', 'DIM-USD', 'DOGE-USD', 'EBTCOLD-USD', 'EDO-USD', 'EMGO-USD', 'ENJ-USD', 'EOS-USD', 'ETC-USD', 'ETH-USD', 'ETP-USD', 'EVX-USD', 'FUEL-USD', 'FUN-USD', 'ICOS-USD', 'ICX-USD', 'KMD-USD', 'LOC-USD', 'LSK-USD', 'LTC-USD', 'MAID-USD', 'MANA-USD', 'MCO-USD', 'NEO-USD', 'NGC-USD', 'NXT-USD', 'OAX-USD', 'OMG-USD', 'PLR-USD', 'PPC-USD', 'PRG-USD', 'QTUM-USD', 'SMART-USD', 'SMS-USD', 'SNC-USD', 'SNT-USD', 'STRAT-USD', 'STU-USD', 'STX-USD', 'SUB-USD', 'SUR-USD', 'SWFTC-USD', 'TNT-USD', 'TRX-USD', 'UGT-USD', 'UTT-USD', 'VEN-USD', 'VERI-USD', 'VIB-USD', 'WMGO-USD', 'WRC-USD', 'XDN-USD', 'XEM-USD', 'XMR-USD', 'XTZ-USD', 'XUC-USD', 'XVG-USD', 'ZEC-USD', 'ZRX-USD', 'ZSC-USD']\n",
    "pairs = pairs\n",
    "df = pd.concat([read_returns(pair).pipe(filter_null_returns).pipe(create_features) for pair in tqdm.tqdm(pairs)]) # Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticks(Dataset):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.x_data = data[:, 1:2].copy().astype('float32')\n",
    "        self.y_data = data[:, -1].copy()#.astype('int')\n",
    "        \n",
    "        indices = pd.DataFrame(data[:, -2] == 0,columns=['isnegative']).reset_index()\n",
    "        positive_indices = indices[~indices.isnegative]['index']\n",
    "        negative_indices = indices[indices.isnegative]['index']\n",
    "        negative_indices_resampled = negative_indices.sample(frac=len(positive_indices)/len(negative_indices))\n",
    "        self.new_indices = pd.np.concatenate([positive_indices, negative_indices_resampled])\n",
    "        self.new_indices.sort()\n",
    "        \n",
    "        self.len = len(self.new_indices) - SEQ_LENGTH - ((len(self.new_indices) - SEQ_LENGTH) % batch_size)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        new_index = self.new_indices[index]\n",
    "        x = self.x_data[new_index: new_index + SEQ_LENGTH]\n",
    "        return x, self.y_data[new_index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "dataset_test = Ticks(df[['time', 'relative_returns', 'buy', 'quantity', 'label', 'label_onehot']].values, BATCH_SIZE)\n",
    "dataloader_test = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38300000/38300000 [02:21<00:00, 270854.36it/s]\n"
     ]
    }
   ],
   "source": [
    "num_positive = 0\n",
    "num_negative = 0\n",
    "\n",
    "for i in tqdm.tqdm(list(range(len(dataset_test)))):\n",
    "    positive = dataset_test[i][1][1] == 1\n",
    "    if positive:\n",
    "        num_positive += 1\n",
    "    else:\n",
    "        num_negative += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19150021\n",
      "19149979\n"
     ]
    }
   ],
   "source": [
    "print(num_positive)\n",
    "print(num_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768239\n",
      "2731761\n"
     ]
    }
   ],
   "source": [
    "print(num_positive)\n",
    "print(num_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Model\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = SEQ_LENGTH\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### (LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # Hidden\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) # Cell state\n",
    "        _, (h_out, _) = self.lstm(x, (h0, c0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        activated = self.sig(out)\n",
    "        return activated\n",
    "\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "test_accuracies = []\n",
    "test_predicted_positives = []\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "lstm = LSTM(NUM_CLASSES, INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
    "lstm.load_state_dict(torch.load('model202.pt', map_location=lambda a, b: a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEUniformLoss(torch.nn.BCELoss):\n",
    "    def forward(self, input, target):\n",
    "        normal_result = super(BCEUniformLoss, self).forward(input, target)\n",
    "        skew = torch.abs(input.data[:, [1]].sum() - trainY[:, [1]].sum())\n",
    "        adjustment_factor = (skew / trainY[:, [1]].sum()) ** 2\n",
    "        return normal_result + normal_result * adjustment_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 10, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#loss_fn = torch.nn.BCELoss()\n",
    "loss_fn = BCEUniformLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:58<00:00, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7198\n",
      "actual positive returns 206133.0/400000: 0.5153325200080872\n",
      "predicted positive_returns 252309/400000: 0.6307725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mikeokslonger/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning:\n",
      "\n",
      "invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_positive_returns = 0\n",
    "predicted_positive_returns = 0\n",
    "num_observations = 0\n",
    "for i, (testX, testY) in tqdm.tqdm(enumerate(dataloader_test), total=len(dataset_test) // BATCH_SIZE):\n",
    "    testX, testY = Variable(testX), Variable(testY)\n",
    "    outputs = lstm(testX)\n",
    "    predicted_labels = torch.max(outputs.data, 1)[1]\n",
    "    correct += predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).sum()\n",
    "    predicted_positive_returns += torch.max(outputs.data, 1)[1].sum()\n",
    "    num_positive_returns += testY[:, [1]].sum()\n",
    "\n",
    "predicted_positive_returns = predicted_positive_returns.item()\n",
    "accuracy = correct.item() / len(dataloader_test.dataset)\n",
    "test_accuracies.append(accuracy)\n",
    "num_positive_returns = num_positive_returns.cpu().data[0]\n",
    "test_predicted_positives.append(predicted_positive_returns/len(dataloader_test.dataset))\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'actual positive returns {num_positive_returns}/{len(dataloader_test.dataset)}: {num_positive_returns/len(dataloader_test.dataset)}')\n",
    "print(f'predicted positive_returns {predicted_positive_returns}/{len(dataloader_test.dataset)}: {predicted_positive_returns/len(dataloader_test.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436/436 [01:59<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6644564220183486\n",
      "actual positive returns 218047.0/436000: 0.5001078248023987\n",
      "predicted positive_returns 256768/436000: 0.5889174311926606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mikeokslonger/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning:\n",
      "\n",
      "invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7171467889908257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#172.pt = 66% accurate, 59% positive\n",
    "#202.pt = 71% accurate, 62% positive\n",
    "#180.pt = 75% accurate, 73% positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(1, 200, batch_first=True)\n",
       "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162802"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ones = (predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).long() & (predicted_labels.cpu().long() == 1).long()).sum()\n",
    "incorrect_ones = ((predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).long() == 0).long() & (predicted_labels.cpu().long() == 1).long()).sum()\n",
    "correct_zeroes = (predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).long() & (predicted_labels.cpu().long() == 0).long()).sum()\n",
    "incorrect_zeroes = ((predicted_labels.cpu().eq(testY.cpu().data[:, [1]].view(-1).long()).long() == 0).long() & (predicted_labels.cpu().long() == 0).long()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43238)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19709)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28856)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8197)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e+05)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_ones + incorrect_ones + correct_zeroes + incorrect_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
